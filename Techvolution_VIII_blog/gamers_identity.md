
# Gamers Identity

In _Techvolution: On the Origin of Technological Species_, I explore how human civilization is fundamentally shaped by technology, not ideology. The book examines our technological nature and its transformative potential across individual identity, political discourse, and economic systems.

The first book is A New Identity. It says the technology we use should be our primary identity because technology now shapes personal capabilities, interactions, and employment potential more than traditional identity markers. But a technological identity does not mean those who use new technology are modern and those who don't aren't.

Here's an example of people using the latest technology still falling prey to the perils of old identities.

Computer gamers, or just "gamers", obviously love games, but but perhaps love gaming hardware even more. They build their own rigs with extravagant lights, cases, and software customizations called "overclocking". Spread across every demographic, together they play games like StarCraft and CounterStrike online for hours as friends, in clans, and make a community tens of millions strong.

Yet, even so, these people have an old identity.

First let's recap. In this "Intel Series" we've learned that electronics depend on transistors which are little switches roughly similar to cells in biology. The more of them a thing has, the more functions and power it is has too. Moore's Law explained that humans double transistors in electronics approximately every two years. So in the 1970s computers had a several thousand transistors and today its tens of billions.

This immense growth in computer power was seen in computation, networking, storage, and graphics. Its why we can take 4k videos video calls today for free when our parents had to pay $5.00 a minute in the 1990s for long distance phone calls.

Gamers obsess over Moore's Law. What processor is best, how much memory should i buy, can my graphics card play the newest game? Shifting through so much advancement is intoxicating but confusing. Gamers needed and demanded help.

Car hobbyists, bakers, movies all have media to discuss and review their respective hobbies. Gamers do too. PC Gamer, GameSpot, Linus Tech Tips, and countless other outlets review the latest games and technology.

There are dozens of nVidia, AMD, Intel, and other choices to choose from. How to compare? Software support, drivers optimizations, and price are important considerations. But there is one easy metric and that's "frames per second" or FPS.

It's like engine horsepower but for gaming computers. When game software is rendered by the computer, we can tell how many "frames" or images are being generated. The more frames, means the more power a computer has, and therefore the better image quality games a computer can power.

Gamers like FPS, gamer media obsess over it.

Each review is filled with "FPS" comparison graphs. Dozens of tests for each new piece of technology. FPS is overwhelmingly the thing a tech journalist focuses on. And, its also the biggest distraction caused by an old, damaging, identity.

Rather than having a new technological identity, gamers have a consumer one.

Today there is huge "AI Tech Boom". Companies like nVidia, AMD, Micron, and others are building the hardware that is fueling this craze. Their valuations are in the trillions of dollars. And yet, each of them have their roots making computer gaming hardware. And today most of them are abandoning the hobby to sell AI hardware.

They can, because the transistors are the same either way. There's no material difference between making a computer gaming graphics card and an artificial intelligence card, except that the latter sells for much more money. Now gamers used to spending thousands are facing building estimates 3 to ten times higher then just a few years ago.

The gamers reaction shows their consumer identity? Here are some recent headlines:

- What's Happening To Our GPUs??
- How Did RAM Get So Expensive? And How it’s Going to Get Worse…
- AMD vows to fight for gamers as DRAM shortage sends GPU prices skyrocketing
- How RAM Shortages Are Making Tech More Expensive & Boring
- WTF Just Happened? | The Corrupt Memory Industry & Micron
- It's An Active Choice to Lie This Much | Micron's "Commitment" to Gamers
- I'm Done Being Mad

AI buying sprees from Amazon, Microsoft and other huge companies, is a few years old. It's only over the past few months that manufacturers decision to abandon the gaming market is leading to gaming hardware shortages. Moore's Law suppl of new transistors are being used to fuel AI chips and not gaming chips.

This is a travesty to the hobby used to getting performance increases every year. It will make the hobby harder to get into for new users. Even Nintendo is projected far less sales. In several years times, if nothing changes, there will be issue with replacing computers that simply die and won't turn on.

And the only thing stopping the gaming industry from avoiding this threat was their consumer identity. If gamers wanted to keep gaming forever, why didn't they buy the companies they were buying from?

Gamers would spend thousands on new tech every few years, but absolutely nothing on buying the companies themselves. From 1990s to 2020s, almost all of Nvidia and AMD sales were from gamers. Their stock prices was from three to 35 dollars for decades. It never occurred to gamers that perhaps they should own a piece of the companies supplying their hobby.

Worst, tech journalists pride themselves on being impartial and refuse any association, never mind ownership of computer makers. As if a gamer making YouTube videos recommending graphic cards with a 5% difference in FPS, is on par with a doctor prescribing medications.

So now their hobby is under threat. I won't do the numbers on how much gamers would have had to spend to own a substantial part of the modern technology industry, because they literally funded almost all of it, and ended up with nothing. At least the DVDs movie philes once splurged on still work. Old gaming hardware is useless after about five, maybe ten, years.

And this is the difference between a old identity rooted in the Industrial Age need for mass consumption, and a modern identity that recognizes technology is not a nice to have. But is the ecosystem is which we harvest our energy, food, housing, communications, and yes, entertainment.

New technology is not the only way, and not always the best, but it is integral to our future. And gamers own none of their future.

It's sad. Never mind the return on investment the individual gamers might have had, it's the lost of say that is most important. Every gaming company has a annual vote to decide their board members, who hire the people that run the company. 

With millions of gamers spending billions of dollars from 1990s to 2020, a relatively few dollars could have been a one-time fee to vote in these elections.

But it didn't happen only becaus of the identity in their heads.

So where does being a "consumer" come from?

- Ironically, Intel's lagging chips made them unattractive to AI purchases. And now, as computer companies are chasing AI dollars, Intel is left to sell to gamers, who've spent years decrying them as being laggers in the Moore's Law race. A truly indicative measure for who entitled consumers see the technological ecosystem will serve them, while they are more like taking what they are given.

## Consumer Identity

The notion of humans primarily as "consumers" emerged in the early 20th century, particularly in the United States. Before this period, frugality and thrift were more valued than continuous consumption.

The rise of mass production, electrification, and marketing techniques transformed how people viewed their economic role. In 1955 "consumerism" was used to reframe the economic system by emphasizing the consumer's central role.

Basically, labelling a person a consumer, meant to turn buying and using things a person's identity. It didn't really matter what, as long as you bought more of it. Hence why homes, cars, and everything else that's filling up homes, garages, and offsite storage sites.

Being a gamer meant being a consumer. The person with the credit card who got decided which technology was the best to buy. But who also did not have a say in the company itself.

And now, the gaming community that funded these companies for decades are being left to die.






## References

Jan 16, 2026. TechLinked. What's Happening To Our GPUs??. https://www.youtube.com/watch?v=1gjRydiVxsc

Jan 2026. Linus Tech Tips. How Did RAM Get So Expensive? And How it’s Going to Get Worse…
https://www.youtube.com/watch?v=iRvyRo5Fk0o&t=146s

Jan 2026. IGN. How RAM Shortages Are Making Tech More Expensive & Boring.  https://www.youtube.com/watch?v=s0CRHyO5mgY.

Dec 2026. Gamers Nexus. WTF Just Happened? | The Corrupt Memory Industry & Micron. https://www.youtube.com/watch?v=9A-eeJP0J7c.

Dec 2026. Gamers Nexus. It's An Active Choice to Lie This Much | Micron's "Commitment" to Gamers. https://www.youtube.com/watch?v=uvahiVBvn9A

Jan 2026. Linus Tech Tips. I'm Done Being Mad. https://www.youtube.com/watch?v=wZZf6LM3wAU.

Jan 16, 2026. Toms Hardware. AMD vows to fight for gamers as DRAM shortage sends GPU prices skyrocketing — Radeon GPU prices have already surged over 10%. https://www.tomshardware.com/pc-components/gpus/amd-vows-to-fight-for-gamers-as-dram-shortage-sends-gpu-prices-skyrocketing-radeon-gpu-prices-have-already-surged-over-10-percent


Oct 15, 2025. Toms Hardware. Adata chairman says AI datacenters are gobbling up hard drives, SSDs, and DRAM alike — insatiable upstream demand could soon lead to consumer shortages. https://www.tomshardware.com/tech-industry/big-tech/adata-chairman-says-ai-datacenters-are-gobbling-up-hard-drives-ssds-and-dram-alike-insatiable-upstream-demand-could-soon-lead-to-consumer-shortages